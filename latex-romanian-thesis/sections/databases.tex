\chapter{Experiments}
Given that at the core of the application are learning algorithms, the system reliability is determined by the databases from which train and test data is used. Although for the face embedding part we were not able to train the neural network ourselves given the limited computational power at our disposal, for the face validation part, the public domain databases offered us a large choice, the most commonly used ones are described in the following sections with the corresponding experiments. In order to learn the face distance threshold, we used another database, MS-Celeb-1M \cite{guo2016msceleb}, but given it's purpose for training neural networks, we only used a small sample which was enough to give us sufficient information about the optimum value of the parameter.
\section{Face spoof databases}
In this section we analyze the accuracy of our LBP-implementation of a face liveness detection method based on the most commonly used anti-spoof face databases available in public domain. We present our intra-database experiments as well as cross-database ones, the latter one being considered better in modeling a real use case.
\subsection{CASIA face antispoofing database }
CASIA database for face antispoofing was created by the Center of Biometrics and Security Research (CBRS) and is composed by 600 videos divided in three categories: low, normal and high quality of 50 asian subjects, 12 videos for each. Out of the 12 videos, 3 are genuine and 9 are fake. There are implemented three face attacks which include: warped photo attack in which the printed photo is bended over the subjects face, cut photo where the eyes on the printed photo are cropped and then position on in front of the subject's face so that the blinking is made possible and video attack replayed on an IPAD.

\subsection{IDIAP Replay-Attack database}
The Replay-Attack Database for face spoofing was produces at the Idiap Research Institute, in Switzerland and it consists of 1300 video clips of photo and video attack attempts to 50 clients, under different lightning conditions. All videos are generated by either having a (real) client trying to access a laptop through a built-in webcam or by displaying a photo or a video recording of the same client for at least 9 seconds. The webcam produces colour videos with a resolution of $320\times240$ pixels. There are two different lightning conditions under which the real and the attack videos were taken: \textit{controlled} where the office light is turned on, blinds are down and background is homogeneous and \textit{adverse} where the blinds are up, more complex background and office light are out. To produce the attacks, high-resolution photos and videos from each client were taken under the same conditions as in their authentication sessions, using a Canon PowerShot SX150 IS camera, which records both 12.1 Mpixel photographs and 720p high-definition video clips. The way to perform the attacks can be divided into two subsets: the first subset is composed of videos generated using a stand to hold the client biometry ("fixed"). For the second set, the attacker holds the device used for the attack with their own hands. In total, 20 attack videos were registered for each client, 10 for each of the attacking modes just described.

\subsection{MSU USSA}
The Michigan State University Unconstrained Smartphone Spoof Attack Database consists of 9.000 images divided into 1.000 live subjects and 8.000 spoof attack. It was created having in mind the that with the release of Android 4.0 millions of devices have the ability to be unlocked using the trusted face functionality therefore in order to simulate the type of attacks that would try this method of security, the spoof attacks were captured using the front and rear camera of a Nexus 5. In order to create the database, 1.000 lives subject images of celebrities from the Weakly Labeled Face Database were selected and for each one four mediums of spoof attacks were recorder: MacBook, Nexus 5, Nvidia Shield Tablet and Printed Photo.
\subsection{MSU MFSD}
Michigan State University Mobile Face Spoof Database was produced at the Michigan State University Pattern Recognition and Image Processing (PRIP) Lab, in East Lansing, US. and contains 280 video clips of photo and video attack attempts to 35 clients. As stated in the description of the database, it has the following properties:
\begin{itemize}
	\item Mobile phone is used to capture both genuine faces and spoof attacks, simulating the application of mobile phone unlock
	\item The printed photos used for attacks are generated with a state of the art color printer on larger sized paper. Hence, the printed photos in the MSU database have much better quality than the printed photos in the Idiap and CASIA databases.
\end{itemize}
Two types of cameras were used to collect the videos: built-in camera in MacBook Air 13” (640x480) and front-facing camera in the Google Nexus 5 Android phone (720x480). Three kinds of spoof medium were used to generate spoof attacks: high-resolution replay video attacks using an iPad Air screen, with resolution of 2048x1536, mobile phone replay video attacks using an iPhone 5S screen, with resolution of 1136x640, printed photo attacks using an A3 paper with fully-occupied printed photo of the client’s biometry, paper size: 11' x 17' (279mm x 432 mm), printed by a HP Color Laserjet CP6015xh printer, with printing resolution of 1200 x 600 dpi. 
\subsection{Inter-database testing}
\section{Face distance threshold}
In order to determine the best value for the face distance threshold which, as described in section \ref{face_recognition} represents the maximum distance between the embeddings of two faces at which we can still consider them as belonging to the same identity, we used a sample from the MS-Celeb-1M database of celebrities faces put together by Microsoft in order to create a benchmark task to recognize one million celebrities from their face images by using as training data all the face images of the individual that are available on the internet. Here we did three experiments in determining the threshold value based on the proposed approach the results of which can be seen in figure \ref{label_here_mofo}. 

\textbf{The first experiment} consisted of randomly selecting \textbf{101} identities and for each one sampling in a random way about \textbf{26} faces. This produced a number of \textbf{2.626} total face images from which we computed \textbf{3.446.625} pairs out of which \textbf{131.300} had the same identity and \textbf{3.315.325} had different identities. This produces a ratio of \textbf{0.03} same identity to different identities pairs.

\textbf{The second experiment} was conducted in the same way as the first one but with different number of subjects, specifically \textbf{316} and about \textbf{20} faces for every identity. This produced a number of \textbf{7900} total face images from which we computed \textbf{59.228.416} pairs out of which \textbf{200.096} had the same identity and \textbf{59.028.320} had different identities. This produces a ratio of \textbf{0.03} same identity to different identities pairs.

\textbf{The third experiment} differed from the first two in that we selected a smaller number of identities but we increased the number of faces per identity. This way we used the online available MS-Celeb-1M sample data containing \textbf{14} identities with approximately \textbf{98} faces per identity. Using this dataset, we had about \textbf{1.274} faces combined together in \textbf{810.901} pairs out of which \textbf{66.542} pairs with faces of the same identity and \textbf{744.359} with different identities, result in a ratio of \textbf{0.09} 	same identity to different identities pairs.

As a result of the three experiments, it can be seen that the embedding function that produces the feature vector used to compute the distances has a stable face distance threshold at around \textbf{1.1} which is invariant to number of identities and face images.